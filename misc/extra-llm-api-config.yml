pytorch_backend_config:
    use_cuda_graph: true
    enable_overlap_scheduler: true
    cuda_graph_max_batch_size: 16
enable_chunked_prefill: true
kv_cache_config:
  free_gpu_memory_fraction: 0.5
